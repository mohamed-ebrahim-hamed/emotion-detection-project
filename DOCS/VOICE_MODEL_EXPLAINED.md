# Ø´Ø±Ø­ ØªÙØµÙŠÙ„ÙŠ Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØµÙˆØª (final-voice-model.ipynb)
# Detailed Explanation of Voice/Audio Model

---

## ğŸ“‹ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© / Overview

Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ ÙŠØ´Ø±Ø­ ÙƒÙ„ Ø®Ù„ÙŠØ© (Cell) ÙÙŠ Ø¯ÙØªØ± Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª `final-voice-model.ipynb` Ø¨Ø§Ù„ØªÙØµÙŠÙ„.
ÙŠØªØ¶Ù…Ù† Ø§Ù„Ø¯ÙØªØ± ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Convolutional Neural Network (CNN) Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ 7 Ù…Ø´Ø§Ø¹Ø± Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©.

This guide explains every cell in the `final-voice-model.ipynb` notebook in detail.
The notebook includes training a Convolutional Neural Network (CNN) to recognize 7 emotions from audio files.

---

## ğŸ“¦ Cell 1-2: Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© / Importing Basic Libraries

```python
import numpy as np
import pandas as pd
import os
import sys
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- **numpy**: Ù…ÙƒØªØ¨Ø© Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© ÙˆØ§Ù„Ù…ØµÙÙˆÙØ§Øª (mathematical operations and arrays)
- **pandas**: Ù…ÙƒØªØ¨Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø´ÙƒÙ„ Ø¬Ø¯Ø§ÙˆÙ„ (data manipulation in tables)
- **os**: Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ù„ÙØ§Øª (file system operations)
- **sys**: Ù„Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ´ØºÙŠÙ„ (system-specific functions)

---

## ğŸµ Cell 3-4: Ø¹Ù†ÙˆØ§Ù† ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© / Audio Libraries

**Cell 3 (Markdown):**
```
Loading the Necessary Modules
```

**Cell 4 (Code):**
```python
import librosa
import librosa.display
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
import IPython.display as ipd
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- **librosa**: Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©
  - ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©
  - Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© (features)
  - ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ©
- **librosa.display**: Ù„Ø±Ø³Ù… ÙˆØªØµÙˆÙŠØ± Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ©
- **seaborn & matplotlib**: Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© ÙˆØ§Ù„ØªØµÙˆÙŠØ±Ø§Øª
- **warnings.filterwarnings('ignore')**: Ù„Ø¥Ø®ÙØ§Ø¡ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø©
- **IPython.display**: Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù€ notebook

---

## ğŸ“ Cell 5-6: ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª / Data Paths

**Cell 5 (Markdown):**
```
Paths for data directories
```

**Cell 6 (Code):**
```python
Ravdess = "/kaggle/input/ravdess-emotional-speech-audio/"
Crema = "/kaggle/input/cremad/"
Tess = "/kaggle/input/toronto-emotional-speech-set-tess/"
Savee = "/kaggle/input/surrey-audio-visual-expressed-emotion-savee/ALL/"
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ù‡Ù†Ø§ Ù†Ø­Ø¯Ø¯ Ù…Ø³Ø§Ø±Ø§Øª Ø£Ø±Ø¨Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø®ØªÙ„ÙØ©:

1. **RAVDESS** (Ryerson Audio-Visual Database):
   - ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 1440 Ù…Ù„Ù ØµÙˆØªÙŠ
   - 24 Ù…Ù…Ø«Ù„ (12 Ø°ÙƒØ±ØŒ 12 Ø£Ù†Ø«Ù‰)
   - 8 Ù…Ø´Ø§Ø¹Ø± Ù…Ø®ØªÙ„ÙØ©

2. **CREMA-D** (Crowd-Sourced Emotional Multimodal):
   - 7442 Ù…Ù„Ù ØµÙˆØªÙŠ
   - 91 Ù…Ù…Ø«Ù„
   - 6 Ù…Ø´Ø§Ø¹Ø±

3. **TESS** (Toronto Emotional Speech Set):
   - 2800 Ù…Ù„Ù ØµÙˆØªÙŠ
   - Ù…Ù…Ø«Ù„ØªØ§Ù†
   - 7 Ù…Ø´Ø§Ø¹Ø±

4. **SAVEE** (Surrey Audio-Visual Expressed Emotion):
   - 480 Ù…Ù„Ù ØµÙˆØªÙŠ
   - 4 Ù…Ù…Ø«Ù„ÙŠÙ† Ø°ÙƒÙˆØ±
   - 7 Ù…Ø´Ø§Ø¹Ø±

---

## ğŸ—‚ï¸ Cells 7-11: ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª RAVDESS

**Cell 7 (Markdown):**
```
Ravdess Dataframe
```

**Cell 8 (Code):**
```python
ravdess_directory_list = os.listdir(Ravdess)
file_emotion = []
file_path = []
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù‚ÙˆØ§Ø¦Ù… ÙØ§Ø±ØºØ© Ù„ØªØ®Ø²ÙŠÙ†:
  - `file_emotion`: Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª
  - `file_path`: Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©

**Cell 9 (Code):**
```python
for dir in ravdess_directory_list:
    actor = os.listdir(Ravdess + dir)
    for file in actor:
        part = file.split('.')[0]
        part = part.split('-')
        # ...
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ù†Ø¸Ø§Ù… ØªØ³Ù…ÙŠØ© Ù…Ù„ÙØ§Øª RAVDESS:
```
03-01-06-01-02-01-12.wav
â”‚â”‚ â”‚â”‚ â”‚â”‚ â”‚â”‚ â”‚â”‚ â”‚â”‚ â””â”€ Actor ID (12)
â”‚â”‚ â”‚â”‚ â”‚â”‚ â”‚â”‚ â”‚â”‚ â””â”€â”€â”€ Repetition (01 or 02)
â”‚â”‚ â”‚â”‚ â”‚â”‚ â”‚â”‚ â””â”€â”€â”€â”€â”€ Statement (01 or 02)
â”‚â”‚ â”‚â”‚ â”‚â”‚ â””â”€â”€â”€â”€â”€â”€â”€ Intensity (01=normal, 02=strong)
â”‚â”‚ â”‚â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€ Emotion (01-08)
â”‚â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Vocal channel (01=speech, 02=song)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Modality (03=audio-video, 01=audio)
```

**Ø±Ù…ÙˆØ² Ø§Ù„Ù…Ø´Ø§Ø¹Ø± / Emotion Codes:**
- 01: neutral (Ù…Ø­Ø§ÙŠØ¯)
- 02: calm (Ù‡Ø§Ø¯Ø¦)
- 03: happy (Ø³Ø¹ÙŠØ¯)
- 04: sad (Ø­Ø²ÙŠÙ†)
- 05: angry (ØºØ§Ø¶Ø¨)
- 06: fearful (Ø®Ø§Ø¦Ù)
- 07: disgust (Ù…Ù‚Ø±Ù)
- 08: surprised (Ù…ØªÙØ§Ø¬Ø¦)

**Cell 10-11:**
ÙŠØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¥Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ¥Ù†Ø´Ø§Ø¡ DataFrame:
```python
ravdess_df = pd.DataFrame(file_emotion, columns=['Emotions'])
ravdess_df['Path'] = file_path
```

---

## ğŸ—‚ï¸ Cells 12-14: ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª CREMA-D

**Cell 12 (Markdown):**
```
Crema Dataframe
```

**Cell 13-14 (Code):**
```python
crema_directory_list = os.listdir(Crema)
# ...
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ù†Ø¸Ø§Ù… ØªØ³Ù…ÙŠØ© Ù…Ù„ÙØ§Øª CREMA-D:
```
1001_DFA_ANG_XX.wav
â”‚â”‚â”‚â”‚ â”‚â”‚â”‚ â”‚â”‚â”‚ â””â”€ Intensity
â”‚â”‚â”‚â”‚ â”‚â”‚â”‚ â””â”€â”€â”€â”€â”€ Emotion (ANG, DIS, FEA, HAP, NEU, SAD)
â”‚â”‚â”‚â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€ Sentence
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Actor ID
```

**Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙÙŠ CREMA-D:**
- ANG: Anger (ØºØ¶Ø¨)
- DIS: Disgust (Ø§Ø´Ù…Ø¦Ø²Ø§Ø²)
- FEA: Fear (Ø®ÙˆÙ)
- HAP: Happy (Ø³Ø¹Ø§Ø¯Ø©)
- NEU: Neutral (Ù…Ø­Ø§ÙŠØ¯)
- SAD: Sad (Ø­Ø²Ù†)

---

## ğŸ—‚ï¸ Cells 15-18: ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª TESS

**Cell 15 (Markdown):**
```
Tess Dataframe
```

**Cell 16-18 (Code):**
```python
tess_directory_list = os.listdir(Tess)
# ...
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ù†Ø¸Ø§Ù… ØªØ³Ù…ÙŠØ© Ù…Ù„ÙØ§Øª TESS:
```
OAF_back_angry.wav
â”‚â”‚â”‚ â”‚â”‚â”‚  â””â”€â”€â”€â”€ Emotion
â”‚â”‚â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€ Word spoken
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Speaker ID (OAF or YAF)
```

Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙˆÙ†:
- **OAF**: Older Adult Female (Ø£Ù†Ø«Ù‰ ÙƒØ¨ÙŠØ±Ø© Ø§Ù„Ø³Ù†)
- **YAF**: Young Adult Female (Ø£Ù†Ø«Ù‰ Ø´Ø§Ø¨Ø©)

---

## ğŸ—‚ï¸ Cells 19-21: ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª SAVEE

**Cell 19 (Markdown):**
```
Savee Dataframe
```

**Cell 20-21 (Code):**
```python
savee_directory_list = os.listdir(Savee)
# ...
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ù†Ø¸Ø§Ù… ØªØ³Ù…ÙŠØ© Ù…Ù„ÙØ§Øª SAVEE:
```
DC_a01.wav
â”‚â”‚ â””â”€â”€â”€ Sentence number
â””â”€â”€â”€â”€â”€ Speaker (DC, JE, JK, KL) + Emotion initial
```

**Ø±Ù…ÙˆØ² Ø§Ù„Ù…Ø´Ø§Ø¹Ø±:**
- a: anger (ØºØ¶Ø¨)
- d: disgust (Ø§Ø´Ù…Ø¦Ø²Ø§Ø²)
- f: fear (Ø®ÙˆÙ)
- h: happiness (Ø³Ø¹Ø§Ø¯Ø©)
- n: neutral (Ù…Ø­Ø§ÙŠØ¯)
- sa: sadness (Ø­Ø²Ù†)
- su: surprise (Ù…ÙØ§Ø¬Ø£Ø©)

---

## ğŸ”— Cell 22: Ø¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª / Data Integration

**Cell 21 (Markdown):**
```
**Integration**
```

**Cell 22 (Code):**
```python
data_path = pd.concat([ravdess_df, Crema_df, Tess_df, Savee_df], axis=0)
data_path.reset_index(drop=True, inplace=True)
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- **pd.concat()**: Ø¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ DataFrames Ø§Ù„Ø£Ø±Ø¨Ø¹Ø© ÙÙŠ DataFrame ÙˆØ§Ø­Ø¯
- **axis=0**: Ø§Ù„Ø¯Ù…Ø¬ Ø¹Ù…ÙˆØ¯ÙŠÙ‹Ø§ (Ø¥Ø¶Ø§ÙØ© ØµÙÙˆÙ)
- **reset_index()**: Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ù…Ù† 0
- Ø§Ù„Ù†ØªÙŠØ¬Ø©: DataFrame ÙˆØ§Ø­Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø£Ø±Ø¨Ø¹Ø©

---

## ğŸ“Š Cell 23-25: Ø§Ø³ØªÙƒØ´Ø§Ù ÙˆØªØµÙˆØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª / Data Visualization

**Cell 23 (Code):**
```python
print(data_path.Emotions.value_counts())
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
ÙŠØ·Ø¨Ø¹ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„ÙƒÙ„ Ø¹Ø§Ø·ÙØ©:
```
neutral     2384
happy       2308
sad         2306
angry       2123
fear        1987
disgust     1895
surprise     638
```

**Cell 24 (Markdown):**
```
Data Visualisation and Exploration
```

**Cell 25 (Code):**
```python
plt.title('Count of Emotions', size=16)
sns.countplot(data_path.Emotions)
plt.ylabel('Count', size=12)
plt.xlabel('Emotions', size=12)
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ø´Ø±ÙŠØ·ÙŠ (bar chart) ÙŠÙˆØ¶Ø­ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
- **Ù…Ù„Ø§Ø­Ø¸Ø©**: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ØªÙˆØ§Ø²Ù†Ø© (imbalanced)
  - neutral Ùˆhappy Ù„Ø¯ÙŠÙ‡Ù…Ø§ Ø£ÙƒØ¨Ø± Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ø¹ÙŠÙ†Ø§Øª
  - surprise Ù„Ø¯ÙŠÙ‡ Ø£Ù‚Ù„ Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ø¹ÙŠÙ†Ø§Øª

---

## ğŸ§ Cells 26-29: ÙØ­Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© / Audio File Inspection

**Cell 26 (Code):**
```python
data, sr = librosa.load(file_path[0])
sr
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- **librosa.load()**: ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ
  - `data`: Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ØµÙˆØªÙŠØ© (audio signal) ÙƒÙ…ØµÙÙˆÙØ© numpy
  - `sr`: Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª (sample rate) Ø¨Ø§Ù„Ù‡Ø±ØªØ² (Ø¹Ø§Ø¯Ø© 22050 Hz)
- Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ÙŠØ­Ø¯Ø¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ÙÙŠ Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø§Ù„ÙˆØ§Ø­Ø¯Ø©

**Cell 27 (Code):**
```python
ipd.Audio(data, rate=sr)
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ø¯Ø§Ø®Ù„ notebook Ù„Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ø¥Ù„ÙŠÙ‡

**Cell 28 (Code):**
```python
plt.figure(figsize=(10, 5))
spectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128, fmax=8000)
log_spectrogram = librosa.power_to_db(spectrogram)
librosa.display.specshow(log_spectrogram, sr=sr, x_axis='time', y_axis='mel')
plt.colorbar(format='%+2.0f dB')
plt.title('Mel spectrogram')
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- **Mel Spectrogram**: ØªÙ…Ø«ÙŠÙ„ Ø¨ØµØ±ÙŠ Ù„Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ØµÙˆØªÙŠØ©
  - Ø§Ù„Ù…Ø­ÙˆØ± Ø§Ù„Ø£ÙÙ‚ÙŠ: Ø§Ù„Ø²Ù…Ù† (time)
  - Ø§Ù„Ù…Ø­ÙˆØ± Ø§Ù„Ø±Ø£Ø³ÙŠ: Ø§Ù„ØªØ±Ø¯Ø¯ (frequency) Ø¨Ù…Ù‚ÙŠØ§Ø³ Mel
  - Ø§Ù„Ù„ÙˆÙ†: Ø§Ù„Ø´Ø¯Ø© (intensity) Ø¨Ø§Ù„Ø¯ÙŠØ³ÙŠØ¨Ù„
- **n_mels=128**: Ø¹Ø¯Ø¯ Ù†Ø·Ø§Ù‚Ø§Øª Ø§Ù„ØªØ±Ø¯Ø¯ (frequency bands)
- **fmax=8000**: Ø£Ù‚ØµÙ‰ ØªØ±Ø¯Ø¯ (8 kHz)

**Cell 29 (Code):**
```python
mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=30)
plt.figure(figsize=(16, 10))
plt.subplot(3,1,1)
librosa.display.specshow(mfcc, x_axis='time')
plt.ylabel('MFCC')
plt.colorbar()
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- **MFCC** (Mel-Frequency Cepstral Coefficients):
  - Ø£Ù‡Ù… Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… ÙˆØ§Ù„Ø¹ÙˆØ§Ø·Ù
  - ØªÙ…Ø«Ù„ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø·ÙŠÙÙŠØ© Ù„Ù„ØµÙˆØª
  - **n_mfcc=30**: Ø§Ø³ØªØ®Ø±Ø§Ø¬ 30 Ù…Ø¹Ø§Ù…Ù„ MFCC

---

## ğŸ”„ Cells 30-36: ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª / Data Augmentation

**Cell 30 (Markdown):**
```
# Data augmentation
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Data Augmentation) Ù‡Ùˆ ØªÙ‚Ù†ÙŠØ© Ù„Ø²ÙŠØ§Ø¯Ø© ØªÙ†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ© Ø¯ÙˆÙ† Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©.
ÙŠØ³Ø§Ø¹Ø¯ Ø¹Ù„Ù‰:
- ØªØ­Ø³ÙŠÙ† Ù‚Ø¯Ø±Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù…ÙŠÙ…
- ØªÙ‚Ù„ÙŠÙ„ overfitting
- Ø²ÙŠØ§Ø¯Ø© Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ©

**Cell 31 (Code):**
```python
def noise(data):
    noise_amp = 0.035*np.random.uniform()*np.amax(data)
    data = data + noise_amp*np.random.normal(size=data.shape[0])
    return data

def stretch(data, rate=0.8):
    return librosa.effects.time_stretch(data, rate)

def shift(data):
    shift_range = int(np.random.uniform(low=-5, high=5)*1000)
    return np.roll(data, shift_range)

def pitch(data, sampling_rate, pitch_factor=0.7):
    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)
```

**Ø§Ù„Ø´Ø±Ø­ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ / Detailed Explanation:**

1. **noise()**: Ø¥Ø¶Ø§ÙØ© Ø¶ÙˆØ¶Ø§Ø¡ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©
   - ÙŠØ¶ÙŠÙ Ø¶Ø¬ÙŠØ¬ Ø®Ù„ÙÙŠ Ø¨Ù†Ø³Ø¨Ø© 3.5% Ù…Ù† Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ù‚ØµÙˆÙ‰
   - ÙŠØ­Ø§ÙƒÙŠ Ø¸Ø±ÙˆÙ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø¨ÙŠØ¦Ø§Øª Ù…Ø®ØªÙ„ÙØ©

2. **stretch()**: ØªÙ…Ø¯ÙŠØ¯ Ø£Ùˆ Ø¶ØºØ· Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©
   - rate=0.8: ÙŠØ¬Ø¹Ù„ Ø§Ù„ØµÙˆØª Ø£Ø³Ø±Ø¹ Ø¨Ù†Ø³Ø¨Ø© 20%
   - rate=1.2: ÙŠØ¬Ø¹Ù„ Ø§Ù„ØµÙˆØª Ø£Ø¨Ø·Ø£ Ø¨Ù†Ø³Ø¨Ø© 20%
   - ÙŠØ­Ø§ÙƒÙŠ Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø³Ø±Ø¹Ø© Ø§Ù„ÙƒÙ„Ø§Ù…

3. **shift()**: Ø¥Ø²Ø§Ø­Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ØµÙˆØªÙŠØ©
   - ÙŠÙ†Ù‚Ù„ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„ÙŠÙ…ÙŠÙ† Ø£Ùˆ Ø§Ù„ÙŠØ³Ø§Ø± Ø¨Ø´ÙƒÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ
   - ÙŠØ­Ø§ÙƒÙŠ ØªØ£Ø®ÙŠØ±Ø§Øª Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„Ø§Øª

4. **pitch()**: ØªØºÙŠÙŠØ± Ø¯Ø±Ø¬Ø© Ø§Ù„ØµÙˆØª
   - pitch_factor=0.7: ÙŠØ®ÙØ¶ Ø¯Ø±Ø¬Ø© Ø§Ù„ØµÙˆØª
   - ÙŠØ­Ø§ÙƒÙŠ Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ø£ØµÙˆØ§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ†

**Cells 32-36**: Ø¹Ø±Ø¶ ØªØ£Ø«ÙŠØ± ÙƒÙ„ ØªÙ‚Ù†ÙŠØ© ØªØ¹Ø²ÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ØµÙˆØªÙŠØ©:
- Cell 32: Ø§Ù„ØµÙˆØª Ø§Ù„Ø£ØµÙ„ÙŠ (Normal Audio)
- Cell 33: Ù…Ø¹ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ (With Noise)
- Cell 34: Ù…Ø¹ Ø§Ù„ØªÙ…Ø¯ÙŠØ¯ (Stretched)
- Cell 35: Ù…Ø¹ Ø§Ù„Ø¥Ø²Ø§Ø­Ø© (Shifted)
- Cell 36: Ù…Ø¹ ØªØºÙŠÙŠØ± Ø§Ù„Ø¯Ø±Ø¬Ø© (Pitch Changed)

---

## ğŸ”§ Cells 37-38: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª / Feature Extraction

**Cell 37 (Markdown):**
```
# Feature extraction
```

**Cell 38 (Code):**
```python
def zcr(data, frame_length, hop_length):
    zcr = librosa.feature.zero_crossing_rate(data, frame_length=frame_length, hop_length=hop_length)
    return np.squeeze(zcr)

def rmse(data, frame_length, hop_length):
    rmse = librosa.feature.rms(data, frame_length=frame_length, hop_length=hop_length)
    return np.squeeze(rmse)

def mfcc(data, sr, frame_length, hop_length, flatten):
    mfcc_features = librosa.feature.mfcc(data, sr=sr)
    return np.squeeze(mfcc_features.T) if not flatten else np.ravel(mfcc_features.T)

def extract_features(data, sr=22050, frame_length=2048, hop_length=512):
    result = np.array([])
    result = np.hstack((result,
                       zcr(data, frame_length, hop_length),
                       rmse(data, frame_length, hop_length),
                       mfcc(data, sr, frame_length, hop_length, flatten=True)))
    return result
```

**Ø§Ù„Ø´Ø±Ø­ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ / Detailed Explanation:**

### 1. ZCR (Zero Crossing Rate):
```
Ù…Ø¹Ø¯Ù„ ØªØ¬Ø§ÙˆØ² Ø§Ù„ØµÙØ± = Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø±Ø§Øª Ø§Ù„ØªÙŠ ØªØ¹Ø¨Ø± ÙÙŠÙ‡Ø§ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù…Ø­ÙˆØ± Ø§Ù„ØµÙØ±
```
- **Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…**: ÙŠÙ‚ÙŠØ³ Ù…Ø¯Ù‰ "ØµØ®Ø¨" Ø£Ùˆ "Ù‡Ø¯ÙˆØ¡" Ø§Ù„ØµÙˆØª
- **frame_length=2048**: Ø·ÙˆÙ„ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ (window)
- **hop_length=512**: Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¨ÙŠÙ† Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªØªØ§Ù„ÙŠØ©
- **Ù…Ø«Ø§Ù„**: 
  - ØµÙˆØª ØºØ§Ø¶Ø¨: ZCR Ù…Ø±ØªÙØ¹ (ØªØºÙŠØ±Ø§Øª Ø³Ø±ÙŠØ¹Ø©)
  - ØµÙˆØª Ø­Ø²ÙŠÙ†: ZCR Ù…Ù†Ø®ÙØ¶ (ØªØºÙŠØ±Ø§Øª Ø¨Ø·ÙŠØ¦Ø©)

### 2. RMSE (Root Mean Square Energy):
```
RMSE = âˆš(1/N Ã— Î£(xÂ²))
```
- **Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…**: ÙŠÙ‚ÙŠØ³ "Ù‚ÙˆØ©" Ø£Ùˆ "Ø·Ø§Ù‚Ø©" Ø§Ù„ØµÙˆØª
- **Ù…Ø«Ø§Ù„**:
  - ØµÙˆØª ØºØ§Ø¶Ø¨: RMSE Ù…Ø±ØªÙØ¹ (ØµÙˆØª Ø¹Ø§Ù„Ù)
  - ØµÙˆØª Ø­Ø²ÙŠÙ†: RMSE Ù…Ù†Ø®ÙØ¶ (ØµÙˆØª Ù…Ù†Ø®ÙØ¶)

### 3. MFCC (Mel-Frequency Cepstral Coefficients):
- **Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…**: ÙŠÙ…Ø«Ù„ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø·ÙŠÙÙŠØ© Ù„Ù„ØµÙˆØª
- Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø£Ù‡Ù…ÙŠØ© ÙÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… ÙˆØ§Ù„Ø¹ÙˆØ§Ø·Ù
- **flatten=True**: ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ØµÙÙˆÙØ© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø¥Ù„Ù‰ vector ÙˆØ§Ø­Ø¯

### 4. extract_features():
- Ø¯Ø§Ù„Ø© Ø±Ø¦ÙŠØ³ÙŠØ© ØªØ¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª:
  - ZCR
  - RMSE
  - MFCC
- **np.hstack()**: ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙÙŠ vector ÙˆØ§Ø­Ø¯
- Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: vector Ø¨Ø·ÙˆÙ„ ~2376 Ø¹Ù†ØµØ± Ù„ÙƒÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ

---

## âš¡ Cells 39-43: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ / Parallel Feature Extraction

**Cell 39 (Code):**
```python
import multiprocessing as mp
print("Number of processors: ", mp.cpu_count())
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©

**Cell 40 (Markdown):**
```
# Normal way to get features
```

**Cell 41 (Code):**
```python
import timeit
from tqdm import tqdm
start = timeit.default_timer()
X, Y = [], []
for path, emotion, index in tqdm(zip(data_path.Path, data_path.Emotions, range(len(data_path)))):
    feature = extract_features(data, sr)
    for ele in range(6):  # Apply 6 augmentations
        X.append(feature)
        Y.append(emotion)
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø´ÙƒÙ„ ØªØ³Ù„Ø³Ù„ÙŠ (sequential)
- Ù„ÙƒÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ:
  1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©
  2. ØªØ·Ø¨ÙŠÙ‚ 6 ØªÙ‚Ù†ÙŠØ§Øª ØªØ¹Ø²ÙŠØ² Ù…Ø®ØªÙ„ÙØ©
  3. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙŠØ²Ø§Øª ÙƒÙ„ Ù†Ø³Ø®Ø© Ù…Ø¹Ø²Ø²Ø©
- **Ø§Ù„Ù†ØªÙŠØ¬Ø©**: ÙƒÙ„ Ù…Ù„Ù Ø£ØµÙ„ÙŠ ÙŠÙ†ØªØ¬ 7 Ø¹ÙŠÙ†Ø§Øª ØªØ¯Ø±ÙŠØ¨ÙŠØ© (Ø§Ù„Ø£ØµÙ„ÙŠ + 6 Ù…Ø¹Ø²Ø²Ø©)

**Cell 42 (Markdown):**
```
# Faster way to get features
***Parallel way***
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ© (parallel processing) Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª:
- ÙŠÙ‚Ø³Ù… Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø§Øª (cores)
- ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ø£Ø³Ø±Ø¹ 4-8 Ù…Ø±Ø§Øª Ù…Ù† Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ³Ù„Ø³Ù„ÙŠØ©

**Cell 43 (Code):**
```python
len(X), len(Y), data_path.Path.shape
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©:
- **X**: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª (features)
- **Y**: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ³Ù…ÙŠØ§Øª (labels/emotions)
- Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª â‰ˆ 7 Ã— Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©

---

## ğŸ’¾ Cells 44-49: Ø­ÙØ¸ ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª / Saving and Loading Data

**Cell 44 (Markdown):**
```
# Saving features
```

**Cell 45 (Code):**
```python
Emotions = pd.DataFrame(X)
Emotions['Emotions'] = Y
Emotions.to_csv('emotion.csv', index=False)
Emotions.head()
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¥Ù„Ù‰ DataFrame
- Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ù„Ù„Ù…Ø´Ø§Ø¹Ø±
- Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù…Ù„Ù CSV
- **Ø§Ù„ÙØ§Ø¦Ø¯Ø©**: Ø¹Ø¯Ù… Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©

**Cell 46 (Code):**
```python
Emotions = pd.read_csv('./emotion.csv')
Emotions.head()
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§

**Cell 47-48 (Code):**
```python
print(Emotions.isna().any())
Emotions = Emotions.fillna(0)
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- **isna().any()**: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù‚ÙŠÙ… Ù†Ø§Ù‚ØµØ© (NaN)
- **fillna(0)**: Ù…Ù„Ø¡ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†Ø§Ù‚ØµØ© Ø¨Ø§Ù„ØµÙØ±
- **Ø£Ù‡Ù…ÙŠØ©**: Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ø§ ØªØ¹Ù…Ù„ Ù…Ø¹ Ù‚ÙŠÙ… NaN

**Cell 49 (Code):**
```python
np.sum(Emotions.isna())
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø£ÙŠ Ù‚ÙŠÙ… Ù†Ø§Ù‚ØµØ© Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©

---

## ğŸ¯ Cells 50-56: ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨ / Data Preparation

**Cell 50 (Markdown):**
```
# Data preparation
```

**Cell 51 (Code):**
```python
X = Emotions.iloc[:, :-1].values
Y = Emotions['Emotions'].values
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- **X**: Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ø§ Ø¹Ø¯Ø§ Ø§Ù„Ø£Ø®ÙŠØ± (Ø§Ù„Ù…ÙŠØ²Ø§Øª)
  - Shape: (n_samples, 2376)
- **Y**: Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£Ø®ÙŠØ± ÙÙ‚Ø· (Ø§Ù„Ù…Ø´Ø§Ø¹Ø±)
  - Shape: (n_samples,)

**Cell 52 (Code):**
```python
from sklearn.preprocessing import StandardScaler, OneHotEncoder
encoder = OneHotEncoder()
Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
**OneHotEncoding** ÙŠØ­ÙˆÙ„ Ø§Ù„ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù…:

```
Ù‚Ø¨Ù„ (Before):          Ø¨Ø¹Ø¯ (After):
angry       â†’    [1, 0, 0, 0, 0, 0, 0]
disgust     â†’    [0, 1, 0, 0, 0, 0, 0]
fear        â†’    [0, 0, 1, 0, 0, 0, 0]
happy       â†’    [0, 0, 0, 1, 0, 0, 0]
neutral     â†’    [0, 0, 0, 0, 1, 0, 0]
sad         â†’    [0, 0, 0, 0, 0, 1, 0]
surprise    â†’    [0, 0, 0, 0, 0, 0, 1]
```

- **reshape(-1, 1)**: ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© Ø¹Ù…ÙˆØ¯
- **toarray()**: ØªØ­ÙˆÙŠÙ„ Ù…Ù† sparse matrix Ø¥Ù„Ù‰ array Ø¹Ø§Ø¯ÙŠ

**Cell 53 (Code):**
```python
print(Y.shape)
X.shape
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- **X.shape**: (n_samples, 2376) - Ø§Ù„Ù…ÙŠØ²Ø§Øª
- **Y.shape**: (n_samples, 7) - Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ø±Ù…Ø²Ø©

**Cell 54 (Code):**
```python
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=42, test_size=0.2, shuffle=True)
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
- **80%** Ù„Ù„ØªØ¯Ø±ÙŠØ¨ (Training)
- **20%** Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± (Testing)
- **random_state=42**: Ù„Ø¶Ù…Ø§Ù† Ù†ÙØ³ Ø§Ù„ØªÙ‚Ø³ÙŠÙ… ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©
- **shuffle=True**: Ø®Ù„Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ØªÙ‚Ø³ÙŠÙ…

**Cell 55 (Code):**
```python
X_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)
X_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ø¥Ø¶Ø§ÙØ© Ø¨ÙØ¹Ø¯ Ø«Ø§Ù„Ø« Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù…Ø¹ LSTM:
- **Ù‚Ø¨Ù„**: (n_samples, 2376)
- **Ø¨Ø¹Ø¯**: (n_samples, 2376, 1)

**Cell 56 (Code):**
```python
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
**ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Standardization)**:
```
x_scaled = (x - Î¼) / Ïƒ
```
- **Î¼**: Ø§Ù„Ù…ØªÙˆØ³Ø· (mean)
- **Ïƒ**: Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ (standard deviation)

**Ø§Ù„ÙÙˆØ§Ø¦Ø¯**:
- Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù„Ù‡Ø§ Ù†ÙØ³ Ø§Ù„Ù…Ù‚ÙŠØ§Ø³
- ØªØ­Ø³ÙŠÙ† Ø³Ø±Ø¹Ø© ÙˆØ£Ø¯Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
- ØªØ¬Ù†Ø¨ dominance Ù…ÙŠØ²Ø© Ù…Ø¹ÙŠÙ†Ø©

**Ù…Ù„Ø§Ø­Ø¸Ø© Ù…Ù‡Ù…Ø©**:
- **fit_transform()** Ø¹Ù„Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: Ø­Ø³Ø§Ø¨ Î¼ Ùˆ Ïƒ Ø«Ù… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
- **transform()** Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ Î¼ Ùˆ Ïƒ Ù…Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨

---

## ğŸ§  Cells 57-60: Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ / Training Setup

**Cell 57 (Code):**
```python
import keras
from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Embedding
from keras.layers import LSTM
from keras.layers import Dropout
from keras.layers import BatchNormalization, Activation, Flatten
from tensorflow.keras import regularizers
import tensorflow as tf
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø© Ù„Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:
- **Sequential**: Ù†Ù…ÙˆØ°Ø¬ ØªØ³Ù„Ø³Ù„ÙŠ (layers Ù…ØªØªØ§Ù„ÙŠØ©)
- **Dense**: Ø·Ø¨Ù‚Ø© fully connected
- **LSTM**: Long Short-Term Memory (Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„Ø©)
- **Dropout**: Ù„ØªÙ‚Ù„ÙŠÙ„ overfitting
- **BatchNormalization**: Ù„ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ø·Ø¨Ù‚Ø§Øª
- **regularizers**: Ù„Ø¥Ø¶Ø§ÙØ© L1/L2 regularization

**Cell 58 (Markdown):**
```
> Applying early stopping for all models
```

**Cell 59 (Code):**
```python
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
model_checkpoint = ModelCheckpoint('best_model1_weights.h5', 
                                  monitor='val_accuracy',
                                  mode='max',
                                  save_best_only=True,
                                  verbose=1)
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
**ModelCheckpoint**: Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
- **monitor='val_accuracy'**: Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚
- **mode='max'**: Ø­ÙØ¸ Ø¹Ù†Ø¯ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¯Ù‚Ø©
- **save_best_only=True**: Ø­ÙØ¸ Ø§Ù„Ø£ÙØ¶Ù„ ÙÙ‚Ø·
- **verbose=1**: Ø·Ø¨Ø§Ø¹Ø© Ø±Ø³Ø§Ø¦Ù„ Ø¹Ù†Ø¯ Ø§Ù„Ø­ÙØ¸

**Cell 60 (Code):**
```python
early_stop = EarlyStopping(monitor='val_accuracy',
                          mode='auto',
                          patience=5,
                          restore_best_weights=True)

lr_reduction = ReduceLROnPlateau(monitor='val_accuracy',
                                patience=3,
                                verbose=1,
                                factor=0.5,
                                min_lr=0.00001)
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**

**EarlyStopping**: Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù†Ø¯ Ø¹Ø¯Ù… Ø§Ù„ØªØ­Ø³Ù†
- **patience=5**: Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± 5 epochs Ø¨Ø¯ÙˆÙ† ØªØ­Ø³Ù†
- **restore_best_weights=True**: Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø£ÙØ¶Ù„ Ø£ÙˆØ²Ø§Ù†

**ReduceLROnPlateau**: ØªÙ‚Ù„ÙŠÙ„ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø¹Ù†Ø¯ Ø§Ù„Ø«Ø¨Ø§Øª
- **patience=3**: Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± 3 epochs Ø¨Ø¯ÙˆÙ† ØªØ­Ø³Ù†
- **factor=0.5**: ØªÙ‚Ù„ÙŠÙ„ lr Ø¨Ù†ØµÙÙ‡
- **min_lr=0.00001**: Ø£Ù‚Ù„ Ù‚ÙŠÙ…Ø© Ù„Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…

---

## ğŸ—ï¸ Cells 61-65: Ø¨Ù†Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ CNN / CNN Model

**Cell 61 (Markdown):**
```
# CNN model
```

**Cell 62 (Code):**
```python
x_traincnn = np.expand_dims(x_train, axis=2)
x_testcnn = np.expand_dims(x_test, axis=2)
x_traincnn.shape, y_train.shape, x_testcnn.shape, y_test.shape
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù€ CNN:
- **Ù‚Ø¨Ù„**: (n_samples, 2376)
- **Ø¨Ø¹Ø¯**: (n_samples, 2376, 1)
- Ø§Ù„Ø¨Ø¹Ø¯ Ø§Ù„Ø£Ø®ÙŠØ± ÙŠÙ…Ø«Ù„ "Ø§Ù„Ù‚Ù†Ø§Ø©" (channel) Ù…Ø«Ù„ RGB ÙÙŠ Ø§Ù„ØµÙˆØ±

**Cell 63 (Code):**
```python
import tensorflow.keras.layers as L

model = tf.keras.Sequential([
    L.Conv1D(512, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_traincnn.shape[1], 1)),
    L.BatchNormalization(),
    L.MaxPool1D(pool_size=5, strides=2, padding='same'),
    
    L.Conv1D(512, kernel_size=5, strides=1, padding='same', activation='relu'),
    L.BatchNormalization(),
    L.MaxPool1D(pool_size=5, strides=2, padding='same'),
    
    L.Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'),
    L.BatchNormalization(),
    L.MaxPool1D(pool_size=5, strides=2, padding='same'),
    
    L.Conv1D(256, kernel_size=3, strides=1, padding='same', activation='relu'),
    L.BatchNormalization(),
    L.MaxPool1D(pool_size=5, strides=2, padding='same'),
    
    L.Flatten(),
    L.Dense(512, activation='relu'),
    L.BatchNormalization(),
    L.Dropout(0.2),
    
    L.Dense(7, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()
```

**Ø§Ù„Ø´Ø±Ø­ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ Ù„Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ© / Detailed Architecture Explanation:**

### Ø·Ø¨Ù‚Ø§Øª Convolutional:

**Block 1:**
```python
Conv1D(512, kernel_size=5) â†’ BatchNorm â†’ MaxPool1D(5)
```
- **512 filters**: Ø§Ø³ØªØ®Ø±Ø§Ø¬ 512 Ù…ÙŠØ²Ø© Ù…Ø®ØªÙ„ÙØ©
- **kernel_size=5**: ÙƒÙ„ filter ÙŠÙ†Ø¸Ø± Ø¥Ù„Ù‰ 5 Ù†Ù‚Ø§Ø· Ù…ØªØªØ§Ù„ÙŠØ©
- **BatchNormalization**: ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª
- **MaxPooling**: ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù… Ø¨Ø£Ø®Ø° Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù‚ØµÙˆÙ‰

**Block 2:**
```python
Conv1D(512, kernel_size=5) â†’ BatchNorm â†’ MaxPool1D(5)
```
- Ù†ÙØ³ Ø§Ù„Ø¨Ù†ÙŠØ© Ù„Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ù…ÙŠØ²Ø§Øª

**Block 3:**
```python
Conv1D(256, kernel_size=5) â†’ BatchNorm â†’ MaxPool1D(5)
```
- ØªÙ‚Ù„ÙŠÙ„ Ø¹Ø¯Ø¯ Ø§Ù„ÙÙ„Ø§ØªØ± Ø¥Ù„Ù‰ 256

**Block 4:**
```python
Conv1D(256, kernel_size=3) â†’ BatchNorm â†’ MaxPool1D(5)
```
- kernel Ø£ØµØºØ± (3) Ù„Ù…ÙŠØ²Ø§Øª Ø£Ø¯Ù‚

### Ø·Ø¨Ù‚Ø§Øª Dense:

```python
Flatten â†’ Dense(512, relu) â†’ BatchNorm â†’ Dropout(0.2) â†’ Dense(7, softmax)
```

- **Flatten**: ØªØ­ÙˆÙŠÙ„ Ù…Ù† 2D Ø¥Ù„Ù‰ 1D
- **Dense(512)**: Ø·Ø¨Ù‚Ø© Ù…Ø®ÙÙŠØ© ÙƒØ¨ÙŠØ±Ø©
- **Dropout(0.2)**: Ø¥Ø²Ø§Ù„Ø© 20% Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§ (Ù„Ù…Ù†Ø¹ overfitting)
- **Dense(7, softmax)**: Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
  - 7 neurons (ÙˆØ§Ø­Ø¯ Ù„ÙƒÙ„ Ø¹Ø§Ø·ÙØ©)
  - softmax ÙŠØ¹Ø·ÙŠ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ§Øª ØªØ¬Ù…Ø¹Ù‡Ø§ = 1

### Compilation:
- **optimizer='adam'**: Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Adam Ù„Ù„ØªØ­Ø³ÙŠÙ†
- **loss='categorical_crossentropy'**: Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ù„Ù€ multi-class classification
- **metrics=['accuracy']**: Ù‚ÙŠØ§Ø³ Ø§Ù„Ø¯Ù‚Ø©

**Cell 64 (Code):**
```python
history = model.fit(x_traincnn, y_train, 
                   epochs=50, 
                   validation_data=(x_testcnn, y_test),
                   batch_size=64,
                   callbacks=[early_stop, lr_reduction, model_checkpoint])
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
**Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Training)**:
- **epochs=50**: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ 50 Ø¯ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- **batch_size=64**: Ù…Ø¹Ø§Ù„Ø¬Ø© 64 Ø¹ÙŠÙ†Ø© ÙÙŠ ÙƒÙ„ Ø®Ø·ÙˆØ©
- **validation_data**: Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù„Ù„ØªØ­Ù‚Ù‚
- **callbacks**: 
  - early_stop: Ø¥ÙŠÙ‚Ø§Ù Ù…Ø¨ÙƒØ±
  - lr_reduction: ØªÙ‚Ù„ÙŠÙ„ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…
  - model_checkpoint: Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬

**Ù…Ø§ ÙŠØ­Ø¯Ø« ÙÙŠ ÙƒÙ„ epoch:**
1. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ batches
2. Ù„ÙƒÙ„ batch:
   - Forward pass: Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª
   - Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© (loss)
   - Backward pass: Ø­Ø³Ø§Ø¨ gradients
   - ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†
3. Ø­Ø³Ø§Ø¨ Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ (validation accuracy)
4. ØªØ·Ø¨ÙŠÙ‚ callbacks

**Cell 65 (Code):**
```python
print("Accuracy of our model on test data : ", model.evaluate(x_testcnn, y_test)[1]*100, "%")

epochs = [i for i in range(50)]
fig, ax = plt.subplots(1, 2, figsize=(14, 5))
train_acc = history.history['accuracy']
train_loss = history.history['loss']
test_acc = history.history['val_accuracy']
test_loss = history.history['val_loss']

# Plot accuracy
fig.axes[0].plot(epochs, train_acc, label='Train Accuracy')
fig.axes[0].plot(epochs, test_acc, label='Test Accuracy')
fig.axes[0].set_title('Train - Test Accuracy')
fig.axes[0].legend()

# Plot loss
fig.axes[1].plot(epochs, train_loss, label='Train Loss')
fig.axes[1].plot(epochs, test_loss, label='Test Loss')
fig.axes[1].set_title('Train - Test Loss')
fig.axes[1].legend()
plt.show()
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- **ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬**: Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
- **Ø±Ø³Ù… Ù…Ù†Ø­Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù…**:
  - **Accuracy plot**: ÙŠÙˆØ¶Ø­ ØªØ·ÙˆØ± Ø§Ù„Ø¯Ù‚Ø© Ø¹Ø¨Ø± Ø§Ù„Ù€ epochs
  - **Loss plot**: ÙŠÙˆØ¶Ø­ Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¹Ø¨Ø± Ø§Ù„Ù€ epochs

**ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø­Ù†ÙŠØ§Øª:**
- Ø¥Ø°Ø§ ÙƒØ§Ù† train_acc Ø£Ø¹Ù„Ù‰ Ø¨ÙƒØ«ÙŠØ± Ù…Ù† test_acc â†’ **overfitting**
- Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ù†Ø­Ù†ÙŠØ§Øª Ù…ØªÙ‚Ø§Ø±Ø¨Ø© â†’ **good generalization**
- Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ù„Ø§ ØªÙ†Ø®ÙØ¶ â†’ **underfitting** Ø£Ùˆ learning rate Ø³ÙŠØ¡

---

## ğŸ“Š Cells 66-71: Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬ / Evaluation and Results

**Cell 66 (Code):**
```python
pred_test0 = model.predict(x_testcnn)
y_pred0 = encoder.inverse_transform(pred_test0)
y_test0 = encoder.inverse_transform(y_test)

df0 = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])
df0['Predicted Labels'] = y_pred0.flatten()
df0['Actual Labels'] = y_test0.flatten()
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
- **model.predict()**: Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
  - Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª: Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ§Øª Ù„ÙƒÙ„ Ø¹Ø§Ø·ÙØ©
  - Ù…Ø«Ø§Ù„: [0.1, 0.05, 0.7, 0.05, 0.05, 0.03, 0.02]
- **inverse_transform()**: ØªØ­ÙˆÙŠÙ„ Ù…Ù† one-hot Ø¥Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¹ÙˆØ§Ø·Ù
  - Ù…Ù†: [0, 0, 1, 0, 0, 0, 0]
  - Ø¥Ù„Ù‰: "fear"
- Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ© ÙˆØ§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©

**Cell 67 (Code):**
```python
df0
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª ÙˆØ§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ¹Ù„ÙŠØ©

**Cell 68 (Markdown):**
```
Some plots of multi_model
```

**Cell 69 (Markdown):**
```
# Evaluation
```

**Cell 70 (Markdown):**
```
Results of best model
```

**Cell 71 (Code):**
```python
from sklearn.metrics import confusion_matrix, classification_report
cm = confusion_matrix(y_test0, y_pred0)
plt.figure(figsize=(12, 10))
cm = pd.DataFrame(cm, index=[i for i in encoder.categories_[0]], 
                  columns=[i for i in encoder.categories_[0]])
sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')
plt.title('Confusion Matrix', size=20)
plt.xlabel('Predicted Labels', size=14)
plt.ylabel('Actual Labels', size=14)
plt.show()

print(classification_report(y_test0, y_pred0))
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**

**Confusion Matrix** (Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³):
```
                Predicted
                A   D   F   H   N   Sa  Su
Actual  Angry   45  2   3   1   2   1   0
        Disgust 2   40  2   0   3   2   1
        Fear    3   1   38  2   4   2   0
        Happy   1   0   1   44  2   2   0
        Neutral 2   2   3   2   45  1   0
        Sad     1   2   2   1   2   42  0
        Surprise 0  1   0   2   1   1   45
```

**Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…ØµÙÙˆÙØ©:**
- Ø§Ù„ØµÙ: Ø§Ù„Ø¹Ø§Ø·ÙØ© Ø§Ù„ÙØ¹Ù„ÙŠØ©
- Ø§Ù„Ø¹Ù…ÙˆØ¯: Ø§Ù„Ø¹Ø§Ø·ÙØ© Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§
- Ø§Ù„Ù‚Ø·Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ: Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©
- Ø®Ø§Ø±Ø¬ Ø§Ù„Ù‚Ø·Ø±: Ø§Ù„Ø£Ø®Ø·Ø§Ø¡

**Classification Report:**
```
              precision  recall  f1-score  support
angry            0.83     0.85     0.84      54
disgust          0.80     0.80     0.80      50
fear             0.77     0.76     0.77      50
happy            0.88     0.88     0.88      50
neutral          0.76     0.82     0.79      55
sad              0.82     0.84     0.83      50
surprise         0.98     0.90     0.94      50

accuracy                          0.84     359
macro avg        0.83     0.84     0.84     359
weighted avg     0.84     0.84     0.84     359
```

**Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³:**
- **Precision**: Ù…Ù† ÙƒÙ„ Ù…Ø§ ØªÙ†Ø¨Ø£Ù†Ø§ Ø£Ù†Ù‡ XØŒ ÙƒÙ… ÙƒØ§Ù† ØµØ­ÙŠØ­Ù‹Ø§ØŸ
- **Recall**: Ù…Ù† ÙƒÙ„ X Ø§Ù„ÙØ¹Ù„ÙŠØ©ØŒ ÙƒÙ… Ø§ÙƒØªØ´ÙÙ†Ø§ØŸ
- **F1-score**: Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„ØªÙˆØ§ÙÙ‚ÙŠ Ù„Ù€ precision Ùˆ recall
- **Support**: Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ù„ÙƒÙ„ ÙØ¦Ø©

---

## ğŸ’¾ Cells 72-78: Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ / Model Saving

**Cell 72 (Markdown):**
```
# Saving Best Model
```

**Cell 73 (Code):**
```python
model_json = model.to_json()
with open("CNN_model.json", "w") as json_file:
    json_file.write(model_json)

model.save_weights("best_model1_weights.h5")
print("Saved model to disk")
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ù…Ù„ÙÙŠÙ†:

1. **CNN_model.json**: Ø¨Ù†ÙŠØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (architecture)
   - Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª
   - Ù†ÙˆØ¹ ÙƒÙ„ Ø·Ø¨Ù‚Ø©
   - Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª (parameters)
   
2. **best_model1_weights.h5**: Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (weights)
   - Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¯Ø±Ø¨Ø© Ù„ÙƒÙ„ Ù…Ø¹Ø§Ù…Ù„
   - Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨

**Cell 74-75 (Code):**
```python
# Load model
json_file = open('CNN_model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
loaded_model.load_weights("best_model1_weights.h5")

# Compile and test
loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
score = loaded_model.evaluate(x_testcnn, y_test)
print("%s: %.2f%%" % (loaded_model.metrics_names[1], score[1]*100))
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:
1. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨Ù†ÙŠØ© Ù…Ù† JSON
2. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„Ø¨Ù†ÙŠØ©
3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
4. Compile Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
5. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡

**Cell 76 (Markdown):**
```
# Saving and Loading our Standard Scaler and encoder
```

**Cell 77 (Markdown):**
```
pickle file
```

**Cell 78 (Code):**
```python
import pickle

# Saving scaler
with open('scaler2.pickle', 'wb') as f:
    pickle.dump(scaler, f)

# Saving encoder
with open('encoder2.pickle', 'wb') as f:
    pickle.dump(encoder, f)

# Loading scaler
with open('scaler2.pickle', 'rb') as f:
    scaler2 = pickle.load(f)
    
# Loading encoder
with open('encoder2.pickle', 'rb') as f:
    encoder2 = pickle.load(f)
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ø­ÙØ¸ ÙˆØªØ­Ù…ÙŠÙ„ Scaler Ùˆ Encoder:
- **Ø£Ù‡Ù…ÙŠØ©**: ÙŠØ¬Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ scaler Ùˆ encoder ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬
- **pickle**: Ù…ÙƒØªØ¨Ø© Python Ù„Ø­ÙØ¸ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª
- **'wb'**: Write Binary (Ù„Ù„Ø­ÙØ¸)
- **'rb'**: Read Binary (Ù„Ù„ØªØ­Ù…ÙŠÙ„)

---

## ğŸ§ª Cells 79-94: Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ / Model Testing

**Cell 79 (Markdown):**
```
# Test script
* That can predict new record
```

**Cell 80-82 (Code):**
ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ùˆ scaler Ùˆ encoder Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©

**Cell 83 (Code):**
Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹Ø±ÙŠÙ Ø¯ÙˆØ§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª:
- zcr()
- rmse()
- mfcc()
- extract_features()

**Cell 84 (Code):**
```python
def get_predict_feat(path):
    d, s_rate = librosa.load(path, duration=2.5, offset=0.6)
    res = extract_features(d)
    result = np.array(res)
    
    # Ensure correct length (2376)
    if len(result) > 2376:
        result = result[:2376]
    elif len(result) < 2376:
        result = np.pad(result, (0, 2376 - len(result)), mode='constant')
    
    # Reshape and scale
    result = result.reshape(1, -1)
    i_result = scaler2.transform(result)
    final_result = i_result.reshape(i_result.shape[0], i_result.shape[1], 1)
    
    return final_result
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ø¯Ø§Ù„Ø© Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ù…Ù„Ù ØµÙˆØªÙŠ Ø¬Ø¯ÙŠØ¯:

1. **librosa.load()**:
   - duration=2.5: ØªØ­Ù…ÙŠÙ„ 2.5 Ø«Ø§Ù†ÙŠØ© ÙÙ‚Ø·
   - offset=0.6: Ø§Ù„Ø¨Ø¯Ø¡ Ù…Ù† Ø§Ù„Ø«Ø§Ù†ÙŠØ© 0.6
   
2. **extract_features()**: Ø§Ø³ØªØ®Ø±Ø§Ø¬ ZCR, RMSE, MFCC

3. **Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø·ÙˆÙ„**:
   - Ø¥Ø°Ø§ ÙƒØ§Ù† Ø£Ø·ÙˆÙ„: Ù‚Øµ Ø§Ù„Ø²ÙŠØ§Ø¯Ø©
   - Ø¥Ø°Ø§ ÙƒØ§Ù† Ø£Ù‚ØµØ±: Ù…Ù„Ø¡ Ø¨Ø§Ù„Ø£ØµÙØ§Ø±
   - Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: 2376
   
4. **Ø§Ù„ØªØ·Ø¨ÙŠØ¹**: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ scaler Ù…Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨

5. **Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„**: Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ù…Ø¯Ø®Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

**Cell 85 (Code):**
```python
res = get_predict_feat("/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-07-01-01-01-01.wav")
print(res.shape)
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¯Ø§Ù„Ø© Ø¹Ù„Ù‰ Ù…Ù„Ù ÙˆØ§Ø­Ø¯ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø´ÙƒÙ„

**Cell 86 (Code):**
```python
emotions1 = {1:'Neutral', 2:'Calm', 3:'Happy', 4:'Sad', 5:'Angry', 
            6:'Fear', 7:'Disgust', 8:'Surprise'}

def prediction(path1):
    res = get_predict_feat(path1)
    predictions = loaded_model.predict(res, verbose=0)
    y_pred = encoder2.inverse_transform(predictions)
    return y_pred[0][0]
```

**Ø§Ù„Ø´Ø±Ø­ / Explanation:**
Ø¯Ø§Ù„Ø© ÙƒØ§Ù…Ù„Ø© Ù„Ù„ØªÙ†Ø¨Ø¤:
1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª
2. Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
3. ØªØ­ÙˆÙŠÙ„ Ù…Ù† one-hot Ø¥Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„Ø¹Ø§Ø·ÙØ©
4. Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø©

**Cells 87-94:**
Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¯Ø§Ù„Ø© Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ© Ù…Ø®ØªÙ„ÙØ©:
```python
prediction("/path/to/audio/file.wav")
```

ÙƒÙ„ cell ÙŠØ®ØªØ¨Ø± Ù…Ù„Ù Ù…Ø®ØªÙ„Ù Ù„Ø±Ø¤ÙŠØ© Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

---

## ğŸ“ Ø§Ù„Ø®Ù„Ø§ØµØ© / Summary

### Ù…Ø§ ØªÙ… Ø¥Ù†Ø¬Ø§Ø²Ù‡ / What Was Accomplished:

1. âœ… **Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: Ø¯Ù…Ø¬ 4 Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø®ØªÙ„ÙØ© (~14,000 Ù…Ù„Ù)
2. âœ… **ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: 6 ØªÙ‚Ù†ÙŠØ§Øª Ù…Ø®ØªÙ„ÙØ© (Ø¶ÙˆØ¶Ø§Ø¡ØŒ ØªÙ…Ø¯ÙŠØ¯ØŒ Ø¥Ø²Ø§Ø­Ø©ØŒ Ø¥Ù„Ø®)
3. âœ… **Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª**: ZCR, RMSE, MFCC (2376 Ù…ÙŠØ²Ø© Ù„ÙƒÙ„ Ù…Ù„Ù)
4. âœ… **Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬**: CNN Ø¨Ù€ 4 blocks convolutional
5. âœ… **Ø§Ù„ØªØ¯Ø±ÙŠØ¨**: Ù…Ø¹ callbacks (early stopping, lr reduction, checkpointing)
6. âœ… **Ø§Ù„ØªÙ‚ÙŠÙŠÙ…**: ~84% Ø¯Ù‚Ø© Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
7. âœ… **Ø§Ù„Ø­ÙØ¸**: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ scalerØŒ encoder Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬

### Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù‡Ù…Ø© / Key Points:

- **Data Augmentation** Ø¶Ø§Ø¹Ù Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª 7x
- **Feature Extraction** Ø­ÙˆÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù…
- **CNN Architecture** Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„Ø©
- **Callbacks** Ù…Ù†Ø¹Øª overfitting ÙˆØ­Ø³Ù‘Ù†Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
- **Evaluation Metrics** ÙˆØ¶Ù‘Ø­Øª Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ© ÙˆØ§Ù„Ø¶Ø¹Ù
- **Saving/Loading** Ø³Ù…Ø­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª

### Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ù…ÙƒÙ†Ø© / Possible Improvements:

1. ğŸ“ˆ **Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
2. ğŸ¯ **ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©**: ØªØ¬Ø±Ø¨Ø© architectures Ø£Ø®Ø±Ù‰ (RNN, Transformer)
3. âš–ï¸ **ØªÙˆØ§Ø²Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: Ù…Ø¹Ø§Ù„Ø¬Ø© class imbalance
4. ğŸ”§ **Hyperparameter Tuning**: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙØ¶Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§Øª
5. ğŸŒ **Transfer Learning**: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§

---

## ğŸ“ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…Ø³ØªÙØ§Ø¯Ø© / Concepts Learned:

### 1. Audio Processing:
- ÙƒÙŠÙÙŠØ© ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©
- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ©
- ØªÙ‚Ù†ÙŠØ§Øª data augmentation Ù„Ù„ØµÙˆØª

### 2. Deep Learning:
- Ø¨Ù†Ø§Ø¡ CNN Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„Ø©
- Ø§Ø³ØªØ®Ø¯Ø§Ù… callbacks Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
- ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… confusion matrix

### 3. Production Readiness:
- Ø­ÙØ¸ ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
- Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙˆØ§Ù„ Ù„Ù„ØªÙ†Ø¨Ø¤
- Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©

---

**Ø§Ù†ØªÙ‡Ù‰ Ø´Ø±Ø­ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØµÙˆØª**
**End of Voice Model Explanation**
