# Emotion Detection Project - Complete Documentation

## ๐ ูุธุฑุฉ ุนุงูุฉ ุนูู ุงููุดุฑูุน / Project Overview

ูุดุฑูุน ุชุญููู ุงููุดุงุนุฑ ูู ุชุทุจูู ููุจ ูุชูุงูู ูุณุชุฎุฏู ุชูููุงุช ุงูุชุนูู ุงูุนููู (Deep Learning) ููุชุนุฑู ุนูู ุงููุดุงุนุฑ ูู ุฎูุงู ูุตุฏุฑูู ูุฎุชูููู:
1. **ุงูุตูุช (Audio)**: ุชุญููู ุงูุชุณุฌููุงุช ุงูุตูุชูุฉ ูููุดู ุนู ุงููุดุงุนุฑ
2. **ุงููุต (Text)**: ุชุญููู ุงููุตูุต ุงูููุชูุจุฉ ูููุดู ุนู ุงููุดุงุนุฑ

This Emotion Detection Project is a comprehensive web application that uses deep learning techniques to recognize emotions from two different sources:
1. **Audio**: Analyzing voice recordings to detect emotions
2. **Text**: Analyzing written text to detect emotions

---

## ๐ฏ ุงููุฏู ูู ุงููุดุฑูุน / Project Goal

ุงููุฏู ุงูุฑุฆูุณู ูู ุจูุงุก ูุธุงู ุฐูู ูุงุฏุฑ ุนูู:
- ุงูุชุนุฑู ุนูู 7 ูุดุงุนุฑ ุฃุณุงุณูุฉ ูู ุงูุตูุช: ุบุงุถุจุ ููุฑูุ ุฎุงุฆูุ ุณุนูุฏุ ุญุฒููุ ูุชูุงุฌุฆุ ูุญุงูุฏ
- ุงูุชุนุฑู ุนูู 28 ุนุงุทูุฉ ูุฎุชููุฉ ูู ุงููุต ุจูุงุกู ุนูู ูุฌููุนุฉ ุจูุงูุงุช GoEmotions
- ุชูููุฑ ูุงุฌูุฉ ููุจ ุณููุฉ ุงูุงุณุชุฎุฏุงู ููุชูุงุนู ูุน ุงูููุงุฐุฌ

The main goal is to build an intelligent system capable of:
- Recognizing 7 basic emotions from audio: angry, disgust, fear, happy, sad, surprise, neutral
- Recognizing 28 different emotions from text based on the GoEmotions dataset
- Providing an easy-to-use web interface for interacting with the models

---

## ๐๏ธ ูุนูุงุฑูุฉ ุงููุดุฑูุน / Project Architecture

```
emotion-detection-project/
โ
โโโ app.py                      # Flask backend application
โโโ requirements.txt            # Python dependencies
โ
โโโ final-voice-model.ipynb    # Audio emotion detection model training
โโโ text-model.ipynb           # Text emotion detection model training
โ
โโโ model/                     # Trained models directory
โ   โโโ CNN_model.json         # Audio model architecture
โ   โโโ best_model1_weights.h5 # Audio model weights
โ   โโโ scaler2.pickle         # Feature scaler for audio
โ   โโโ encoder2.pickle        # Label encoder for audio
โ   โโโ Text Model/            # Text model (DistilBERT)
โ
โโโ templates/                 # HTML templates
โ   โโโ index.html            # Main page
โ   โโโ about.html            # About page
โ   โโโ result.html           # Results page
โ
โโโ static/                    # Static files (CSS, JS)
โ   โโโ css/
โ   โโโ js/
โ
โโโ testSounds/               # Sample audio files for testing
โ
โโโ uploads/                  # Temporary uploads folder
โ
โโโ DOCS/                     # Documentation folder
    โโโ README.md             # Main documentation (this file)
    โโโ VOICE_MODEL_EXPLAINED.md  # Cell-by-cell explanation of audio model
    โโโ TEXT_MODEL_EXPLAINED.md   # Cell-by-cell explanation of text model
    โโโ API_DOCUMENTATION.md      # API endpoints documentation
    โโโ USAGE_GUIDE.md            # User guide with examples
```

---

## ๐ง ุงูููููุงุช ุงูุฑุฆูุณูุฉ / Main Components

### 1. ูููุฐุฌ ุงูุตูุช / Audio Model
- **ุงูููุน**: Convolutional Neural Network (CNN)
- **ุงููุฏุฎูุงุช**: ูููุงุช ุตูุชูุฉ (WAV, MP3, M4A, OGG, WEBM)
- **ุงููุฎุฑุฌุงุช**: 7 ูุดุงุนุฑ ุฃุณุงุณูุฉ
- **ุงูููุฒุงุช ุงููุณุชุฎุฏูุฉ**: 
  - Zero Crossing Rate (ZCR)
  - Root Mean Square Energy (RMSE)
  - Mel-Frequency Cepstral Coefficients (MFCC)

### 2. ูููุฐุฌ ุงููุต / Text Model
- **ุงูููุน**: DistilBERT (Transformer-based)
- **ุงููุฏุฎูุงุช**: ูุตูุต ุนุฑุจูุฉ ุฃู ุฅูุฌููุฒูุฉ
- **ุงููุฎุฑุฌุงุช**: 28 ุนุงุทูุฉ ูุฎุชููุฉ
- **ูุฌููุนุฉ ุงูุจูุงูุงุช**: GoEmotions

### 3. ุชุทุจูู Flask / Flask Application
- **ุงูุฅุทุงุฑ**: Flask (Python Web Framework)
- **ุงููุธุงุฆู**:
  - ุฑูุน ูุชุญููู ุงููููุงุช ุงูุตูุชูุฉ
  - ุฅุฏุฎุงู ูุชุญููู ุงููุตูุต
  - ุนุฑุถ ุงููุชุงุฆุฌ ุจุดูู ุชูุงุนูู
  - ุฏุนู ุงููุบุฉ ุงูุนุฑุจูุฉ

---

## ๐ ูุฌููุนุงุช ุงูุจูุงูุงุช ุงููุณุชุฎุฏูุฉ / Datasets Used

### ูููููุฐุฌ ุงูุตูุชู / For Audio Model:
1. **RAVDESS** (Ryerson Audio-Visual Database of Emotional Speech and Song)
2. **CREMA-D** (Crowd-sourced Emotional Multimodal Actors Dataset)
3. **TESS** (Toronto Emotional Speech Set)
4. **SAVEE** (Surrey Audio-Visual Expressed Emotion)

### ูููููุฐุฌ ุงููุตู / For Text Model:
1. **GoEmotions**: ูุฌููุนุฉ ุจูุงูุงุช ูู Google ุชุญุชูู ุนูู 58,000 ุชุนููู ูู Reddit ูุตููุฉ ุฅูู 28 ุนุงุทูุฉ

---

## ๐ ุงูุชุซุจูุช ูุงูุฅุนุฏุงุฏ / Installation and Setup

### ุงููุชุทูุจุงุช / Requirements:
- Python 3.7+
- TensorFlow 2.4.1
- PyTorch (ูููููุฐุฌ ุงููุตู / for text model)
- Flask 2.2.5
- librosa 0.8.1
- transformers (ูููููุฐุฌ ุงููุตู / for text model)

### ุฎุทูุงุช ุงูุชุซุจูุช / Installation Steps:

```bash
# 1. ูุณุฎ ุงููุดุฑูุน / Clone the repository
git clone https://github.com/mohamed-ebrahim-hamed/emotion-detection-project.git
cd emotion-detection-project

# 2. ุชุซุจูุช ุงูููุชุจุงุช ุงููุทููุจุฉ / Install required packages
pip install -r requirements.txt

# 3. ุชุญููู ุงูููุงุฐุฌ ุงููุฏุฑุจุฉ / Download pre-trained models
# Download from the provided Google Drive links and place in model/ directory

# 4. ุชุดุบูู ุงูุชุทุจูู / Run the application
python app.py

# 5. ูุชุญ ุงููุชุตูุญ / Open browser
# Navigate to http://localhost:5000
```

---

## ๐จ ุงููุดุงุนุฑ ุงููุฏุนููุฉ / Supported Emotions

### ุงููููุฐุฌ ุงูุตูุชู / Audio Model (7 Emotions):
| Emotion | Arabic | Emoji | Color |
|---------|--------|-------|-------|
| Angry | ุบุงุถุจ | ๐ | #FF6B6B |
| Disgust | ููุฑู | ๐คข | #8AC926 |
| Fear | ุฎุงุฆู | ๐จ | #7209B7 |
| Happy | ุณุนูุฏ | ๐ | #FFD166 |
| Sad | ุญุฒูู | ๐ข | #118AB2 |
| Surprise | ูุชูุงุฌุฆ | ๐ฒ | #EF476F |
| Neutral | ูุญุงูุฏ | ๐ | #06D6A0 |

### ุงููููุฐุฌ ุงููุตู / Text Model (28 Emotions):
ุฅุนุฌุงุจุ ุชุณููุฉุ ุบุถุจุ ุงูุฒุนุงุฌุ ููุงููุฉุ ุงูุชูุงูุ ุงุฑุชุจุงูุ ูุถููุ ุฑุบุจุฉุ ุฎูุจุฉ ุฃููุ ุฑูุถุ ุงุดูุฆุฒุงุฒุ ุฅุญุฑุงุฌุ ุญูุงุณุ ุฎููุ ุงูุชูุงูุ ุญุฒู ุดุฏูุฏุ ูุฑุญุ ุญุจุ ุชูุชุฑุ ูุญุงูุฏุ ุชูุงุคูุ ูุฎุฑุ ุฅุฏุฑุงูุ ุงุฑุชูุงุญุ ูุฏูุ ุญุฒูุ ููุงุฌุฃุฉ

---

## ๐ ููููุฉ ุนูู ุงูููุงุฐุฌ / How the Models Work

### ูููุฐุฌ ุงูุตูุช / Audio Model:

1. **ุชุญููู ุงูููู ุงูุตูุชู** / Load audio file
2. **ุชุญููู ุงูุตูุบุฉ ุฅุฐุง ูุฒู ุงูุฃูุฑ** / Convert format if needed (using ffmpeg)
3. **ุงุณุชุฎุฑุงุฌ ุงูููุฒุงุช** / Extract features:
   - ZCR: ูุนุฏู ุชุฌุงูุฒ ุงูุตูุฑ (ูููุณ ุงูุชุบูุฑุงุช ูู ุงูุฅุดุงุฑุฉ)
   - RMSE: ุฌุฐุฑ ูุชูุณุท ูุฑุจุน ุงูุทุงูุฉ (ูููุณ ููุฉ ุงูุตูุช)
   - MFCC: ูุนุงููุงุช ุณูุจุณุชุฑุงู ููู (ุชูุซู ุงูุฎุตุงุฆุต ุงูุทูููุฉ)
4. **ุชุทุจูุน ุงูููุฒุงุช** / Normalize features using StandardScaler
5. **ุงูุชูุจุค ุจุงุณุชุฎุฏุงู CNN** / Predict using CNN model
6. **ุฅุฑุฌุงุน ุงููุชูุฌุฉ** / Return emotion with confidence score

### ูููุฐุฌ ุงููุต / Text Model:

1. **ุงุณุชูุจุงู ุงููุต** / Receive text input
2. **ุชุฌุฒุฆุฉ ุงููุต** / Tokenize text using DistilBERT tokenizer
3. **ุชุญููู ุฅูู ุชูุณูู ููุงุณุจ** / Convert to model format
4. **ุงูุชูุจุค ุจุงุณุชุฎุฏุงู DistilBERT** / Predict using DistilBERT
5. **ุญุณุงุจ ุงูุงุญุชูุงููุงุช** / Calculate probabilities for all 28 emotions
6. **ุฅุฑุฌุงุน ุงูุนูุงุทู ุงูููุชุดูุฉ** / Return detected emotions (threshold > 0.3)

---

## ๐ก ููุงุท ุงูููุงูุฉ API / API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | ุงูุตูุญุฉ ุงูุฑุฆูุณูุฉ / Main page |
| `/predict` | POST | ุชุญููู ุงูููู ุงูุตูุชู / Analyze audio file |
| `/predict-text` | POST | ุชุญููู ุงููุต / Analyze text |
| `/health` | GET | ุงูุชุญูู ูู ุญุงูุฉ ุงูุชุทุจูู / Check application health |
| `/test-model` | GET | ุงุฎุชุจุงุฑ ุงููููุฐุฌ / Test model |

ูููุฒูุฏ ูู ุงูุชูุงุตููุ ุฑุงุฌุน / For more details, see: [API_DOCUMENTATION.md](./API_DOCUMENTATION.md)

---

## ๐ ุงููุซุงุฆู ุงูุชูุตูููุฉ / Detailed Documentation

1. **[VOICE_MODEL_EXPLAINED.md](./VOICE_MODEL_EXPLAINED.md)**
   - ุดุฑุญ ุชูุตููู ููู ุฎููุฉ ูู final-voice-model.ipynb
   - Detailed cell-by-cell explanation of the audio model notebook

2. **[TEXT_MODEL_EXPLAINED.md](./TEXT_MODEL_EXPLAINED.md)**
   - ุดุฑุญ ุชูุตููู ููู ุฎููุฉ ูู text-model.ipynb
   - Detailed cell-by-cell explanation of the text model notebook

3. **[API_DOCUMENTATION.md](./API_DOCUMENTATION.md)**
   - ูุซุงุฆู API ุงููุงููุฉ ูุน ุฃูุซูุฉ
   - Complete API documentation with examples

4. **[USAGE_GUIDE.md](./USAGE_GUIDE.md)**
   - ุฏููู ุงูุงุณุชุฎุฏุงู ูุน ุฃูุซูุฉ ุนูููุฉ
   - Usage guide with practical examples

---

## ๐ ุงูุชูููุงุช ุงููุณุชุฎุฏูุฉ / Technologies Used

### Backend:
- **Python 3.7+**
- **Flask**: ุฅุทุงุฑ ุชุทููุฑ ุงูููุจ
- **TensorFlow/Keras**: ูููููุฐุฌ ุงูุตูุชู (CNN)
- **PyTorch**: ูููููุฐุฌ ุงููุตู (DistilBERT)
- **librosa**: ููุนุงูุฌุฉ ุงูุตูุช
- **transformers**: ููููุฐุฌ ุงููุบุฉ

### Frontend:
- **HTML5**
- **CSS3**
- **JavaScript**
- **Bootstrap** (ุฅู ูุฌุฏ)

### Machine Learning:
- **Convolutional Neural Networks (CNN)**
- **Transformer Architecture (DistilBERT)**
- **Feature Extraction Techniques**
- **Data Augmentation**

---

## ๐ ุงูุฃุฏุงุก / Performance

### ูููุฐุฌ ุงูุตูุช / Audio Model:
- **ุงูุฏูุฉ**: ~75% ุนูู ุจูุงูุงุช ุงูุงุฎุชุจุงุฑ
- **ููุช ุงูุชูุจุค**: ~2-3 ุซูุงูู ููู ููู ุตูุชู

### ูููุฐุฌ ุงููุต / Text Model:
- **ุงูุฏูุฉ**: ูุชุบูุฑุฉ ุญุณุจ ุงูุนุงุทูุฉ (F1-score ุนูู GoEmotions)
- **ููุช ุงูุชูุจุค**: ~1 ุซุงููุฉ ููู ูุต

---

## ๐ ุงูุฃูุงู / Security

- **ุงูุชุญูู ูู ููุน ุงููููุงุช**: ููุท ุตูุบ ุงูุตูุช ุงููุณููุญ ุจูุง
- **ุญุฏ ุฃูุตู ูุญุฌู ุงูููู**: 16 ููุฌุงุจุงูุช
- **ุชูุธูู ุงููููุงุช ุงููุคูุชุฉ**: ุญุฐู ุชููุงุฆู ุจุนุฏ ุงููุนุงูุฌุฉ
- **ูุนุงูุฌุฉ ุงูุฃุฎุทุงุก**: ุชุณุฌูู ุดุงูู ููุฃุฎุทุงุก

---

## ๐ ุงุณุชูุดุงู ุงูุฃุฎุทุงุก / Troubleshooting

### ูุดููุฉ: ุงููููุฐุฌ ูุง ูุชุญูู
**ุงูุญู**: 
- ุชุฃูุฏ ูู ูุฌูุฏ ูููุงุช ุงููููุฐุฌ ูู ุงููุณุงุฑ ุงูุตุญูุญ
- ุชุญูู ูู ุตูุบุฉ ุงููููุงุช (JSON, H5, pickle)

### ูุดููุฉ: ุฎุทุฃ ูู ุชุญููู ุงูุตูุช
**ุงูุญู**: 
- ุชุฃูุฏ ูู ุชุซุจูุช ffmpeg: `conda install -c conda-forge ffmpeg`

### ูุดููุฉ: ุงููููุฐุฌ ุงููุตู ุบูุฑ ูุชููุฑ
**ุงูุญู**: 
- ุซุจุช ุงูููุชุจุงุช ุงููุทููุจุฉ: `pip install torch transformers soxr`

---

## ๐ค ุงููุณุงููุฉ / Contributing

ูุฑุญุจ ุจุงููุณุงููุงุช! ูุฑุฌู:
1. Fork ุงููุดุฑูุน
2. ุฅูุดุงุก branch ุฌุฏูุฏ (`git checkout -b feature/AmazingFeature`)
3. Commit ุงูุชุบููุฑุงุช (`git commit -m 'Add some AmazingFeature'`)
4. Push ุฅูู Branch (`git push origin feature/AmazingFeature`)
5. ูุชุญ Pull Request

---

## ๐ ุงูุชุฑุฎูุต / License

ูุฐุง ุงููุดุฑูุน ูุฑุฎุต ุชุญุช MIT License

---

##
