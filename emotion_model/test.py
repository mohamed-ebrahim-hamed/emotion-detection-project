import torch
import numpy as np
from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification

# ===== ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ù€ Tokenizer =====
MODEL_PATH = "D:/results/emotion_model"  # Ø§Ù„Ù…Ø³Ø§Ø± Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©

model = DistilBertForSequenceClassification.from_pretrained(MODEL_PATH)
tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_PATH)

# Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¬Ù‡Ø§Ø²
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)
model.eval()

print(f"âœ… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡ Ø¹Ù„Ù‰: {device}")

# ===== ØªØ­Ù…ÙŠÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù€ Emotions =====
# Ù„Ùˆ Ø¹Ù†Ø¯Ùƒ Ù…Ù„Ù emotions.txt
EMOTIONS_FILE = "D:/results/emotions.txt"  # Ø£Ùˆ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­
try:
    with open(EMOTIONS_FILE) as f:
        emotion_names = [line.strip() for line in f]
except:
    # Ø§Ù„Ù€ 28 emotions Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
    emotion_names = [
        "admiration", "amusement", "anger", "annoyance", "approval", "caring",
        "confusion", "curiosity", "desire", "disappointment", "disapproval",
        "disgust", "embarrassment", "excitement", "fear", "gratitude", "grief",
        "joy", "love", "nervousness", "neutral", "optimism", "pride",
        "realization", "relief", "remorse", "sadness", "surprise"
    ]


# ===== Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ =====
def predict_emotions(text, threshold=0.5):
    """
    Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù€ Emotions Ù…Ù† Ù†Øµ

    Args:
        text: Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„Ù‡
        threshold: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ù€ probability

    Returns:
        dict: Ø§Ù„Ù€ emotions ÙˆØ§Ù„Ù€ scores
    """
    # Tokenization
    inputs = tokenizer(
        text,
        truncation=True,
        padding="max_length",
        max_length=128,
        return_tensors="pt"
    )

    input_ids = inputs["input_ids"].to(device)
    attention_mask = inputs["attention_mask"].to(device)

    # Prediction
    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        probabilities = torch.sigmoid(logits)  # multi-label

    probs = probabilities.cpu().numpy()[0]

    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    results = {
        emotion: float(prob)
        for emotion, prob in zip(emotion_names, probs)
        if prob > threshold
    }

    # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ù€ score
    results = dict(sorted(results.items(), key=lambda x: x[1], reverse=True))

    return results


# ===== Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª =====
test_texts = [
    "I love this!  This is amazing!",
    "I'm so angry right now!",
    "This is disappointing and sad",
    "I feel confused about this situation",
    ''
]

print("\n" + "=" * 60)
print("ğŸ§ª Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±:")
print("=" * 60)

for text in test_texts:
    print(f"\nğŸ“ Ø§Ù„Ù†Øµ: {text}")
    results = predict_emotions(text, threshold=0.3)

    if results:
        for emotion, score in results.items():
            print(f"   â€¢ {emotion}: {score:.3f}")
    else:
        print("   Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù emotions")
